{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#os.environ['TF_cpp_MIN_LEVEL'] =  '2'all_model\n",
    "#from tensorflow.keras.layers import Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.csv: Exist.\n",
      "Add class: 0 \n",
      "-----------------\n",
      "Frames per second: 29.97002997002997\n",
      "Frame count: 3270\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 287>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000001?line=307'>308</a>\u001b[0m     \u001b[39mprint\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset_csv_file\u001b[39m}\u001b[39;00m\u001b[39m: Exist.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000001?line=308'>309</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAdd class: \u001b[39m\u001b[39m{\u001b[39;00madd_class\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m-----------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000001?line=310'>311</a>\u001b[0m     add_record_coordinates(cap\u001b[39m=\u001b[39;49mcap, class_name\u001b[39m=\u001b[39;49madd_class, export_csv\u001b[39m=\u001b[39;49mdataset_csv_file)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000001?line=311'>312</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000001?line=312'>313</a>\u001b[0m     \u001b[39mprint\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset_csv_file\u001b[39m}\u001b[39;00m\u001b[39m: Not exist.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb Cell 3'\u001b[0m in \u001b[0;36madd_record_coordinates\u001b[0;34m(cap, class_name, export_csv)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000001?line=265'>266</a>\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000001?line=267'>268</a>\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mRaw Webcam Feed\u001b[39m\u001b[39m'\u001b[39m, image)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000001?line=269'>270</a>\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m10\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000001?line=270'>271</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000001?line=271'>272</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def mediapipe_detections(cap):\n",
    "    '''# 1. Make Some Detections with a video # '''\n",
    "    if (cap.isOpened() == False):\n",
    "        print(\"Error opening the video file.\")\n",
    "    else:\n",
    "        input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(f'Frames per second: {input_fps}')\n",
    "        print(f'Frame count: {frame_count}')\n",
    "    \n",
    "    # Color difine\n",
    "    #color_face1 = (71, 146, 253)\n",
    "    color_face2 = (71, 146, 253)\n",
    "    color_r_hand1 = (71, 146, 253)\n",
    "    color_r_hand2 = (71, 146, 253)\n",
    "    color_l_hand1 = (71, 146, 253)\n",
    "    color_l_hand2 = (71, 146, 253)\n",
    "    color_pose1 = (71, 146, 253)\n",
    "    color_pose2 = (71, 146, 253)\n",
    "\n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils # Drawing helpers.\n",
    "    mp_holistic = mp.solutions.holistic     # Mediapipe Solutions.\n",
    "\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "                # print(results.face_landmarks)\n",
    "\n",
    "                # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                '''# 1. Draw face landmarks\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_face1, thickness=1, circle_radius=1),\n",
    "                    mp_drawing.DrawingSpec(color=color_face2, thickness=1, circle_radius=1)\n",
    "                )\n",
    "\n",
    "                # 2. Right hand\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_r_hand1, thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=color_r_hand2, thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_l_hand1, thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=color_l_hand2, thickness=2, circle_radius=2)\n",
    "                )'''\n",
    "\n",
    "                # 4. Pose Detections\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=(71, 146, 253), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(71, 146, 253), thickness=2, circle_radius=2)\n",
    "                )\n",
    "            \n",
    "\n",
    "                cv2.imshow('Raw Video Feed', image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    print('Done.')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def create_pose_csv(cap, create_csv):\n",
    "    ''' Create pose detections csv  with a video.'''\n",
    "    if (cap.isOpened() == False):\n",
    "        print(\"\\nError opening the video file.\")\n",
    "        return\n",
    "    else:\n",
    "        pass\n",
    "        # input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        # frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        # print(f'Frames per second: {input_fps}')\n",
    "        # print(f'Frame count: {frame_count}')\n",
    "\n",
    "    # Color difine\n",
    "    color_face1 = (80,110,10)\n",
    "    color_face2 = (80,256,121)\n",
    "    color_r_hand1 = (80,22,10)\n",
    "    color_r_hand2 = (80,44,121)\n",
    "    color_l_hand1 = (121,22,76)\n",
    "    color_l_hand2 = (121,44,250)\n",
    "    color_pose1 = (121,44,250)\n",
    "    color_pose2 = (121,44,250)\n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils # Drawing helpers.\n",
    "    mp_holistic = mp.solutions.holistic     # Mediapipe Solutions.\n",
    "\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "                # print(results.face_landmarks)\n",
    "\n",
    "                # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                '''# 1. Draw face landmarks\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_face1, thickness=1, circle_radius=1),\n",
    "                    mp_drawing.DrawingSpec(color=color_face2, thickness=1, circle_radius=1)\n",
    "                )\n",
    "\n",
    "                # 2. Right hand\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_r_hand1, thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=color_r_hand2, thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_l_hand1, thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=color_l_hand2, thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "                # 4. Pose Detections\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_pose1, thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=color_pose2, thickness=2, circle_radius=2)\n",
    "                )'''\n",
    "\n",
    "                try:\n",
    "                    num_coords = len(results.pose_landmarks.landmark) # num_coords: 33\n",
    "\n",
    "                    landmarks = ['class'] # Create first rows data.\n",
    "                    for val in range(1, num_coords+1):\n",
    "                        landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "                    \n",
    "                    # E.g., (pose+face)2005=1+501*4, (pose+r_hand)217=1+54*4, 133=1+33*4\n",
    "                    # print(f'len(landmarks): {len(landmarks)}')\n",
    "\n",
    "                    # Define first class rows in csv file.\n",
    "                    with open(create_csv, mode='w', newline='') as f:\n",
    "                        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        csv_writer.writerow(landmarks)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                cv2.imshow('Raw Video Feed', image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print(f'\\nCreate {dataset_csv_file} done! \\n\\nNow you can run again.')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def add_record_coordinates(cap, class_name, export_csv):\n",
    "    if (cap.isOpened() == False):\n",
    "        print(\"Error opening the video file.\")\n",
    "    else:\n",
    "        input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(f'Frames per second: {input_fps}')\n",
    "        print(f'Frame count: {frame_count}')\n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils # Drawing helpers.\n",
    "    mp_holistic = mp.solutions.holistic     # Mediapipe Solutions.\n",
    "\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "                # print(results.face_landmarks)\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                '''# 1. Draw face landmarks\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                    mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                )\n",
    "\n",
    "                # 2. Right hand\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                )'''\n",
    "\n",
    "                # 4. Pose Detections\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                )\n",
    "                # Export coordinates\n",
    "                try:\n",
    "                    # Extract Pose landmarks\n",
    "                    pose = results.pose_landmarks.landmark\n",
    "                    pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "                    # Extract Face landmarks\n",
    "                    # face = results.face_landmarks.landmark\n",
    "                    # face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "                    \n",
    "                    # Concate rows\n",
    "                    # row = pose_row+face_row\n",
    "                    row = pose_row\n",
    "\n",
    "                    # Append class name.\n",
    "                    row.insert(0, class_name)\n",
    "\n",
    "                    # Export to CSV\n",
    "                    with open(export_csv, mode='a', newline='') as f:\n",
    "                        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        csv_writer.writerow(row) \n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "    print('Add done!\\n -------------------')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # check_csv_contents(file=export_csv)\n",
    "\n",
    "\n",
    "def check_csv_contents(file):\n",
    "    df = pd.read_csv(file)\n",
    "    print(f'Top5 datas: \\n{df.head()}')\n",
    "    print(f'Last5 datas: \\n{df.tail()}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    n = 0\n",
    "\n",
    "    # 0: cat_camel, 1: bridge_exercise, 2: heel_raise\n",
    "    category = [0, 1, 2]\n",
    "    video_file_name = 'videoplayback' + '1'\n",
    "    \n",
    "    # Add n categories of pose.\n",
    "    add_class = category[n]\n",
    "\n",
    "    # Can create train dataset or test dataset.\n",
    "    dataset_csv_file = '2.csv'\n",
    "\n",
    "    video_path = \"\" + video_file_name +\".mp4\"\n",
    "    output_video = video_file_name + \"_out.mp4\"\n",
    "\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if os.path.isfile(dataset_csv_file):\n",
    "        print (f'{dataset_csv_file}: Exist.')\n",
    "        print(f'Add class: {add_class} \\n-----------------')\n",
    "\n",
    "        add_record_coordinates(cap=cap, class_name=add_class, export_csv=dataset_csv_file)\n",
    "    else:\n",
    "        print (f'{dataset_csv_file}: Not exist.')\n",
    "        print('\\nInitiate creating a csv file....\\n')\n",
    "        create_pose_csv(cap, create_csv=dataset_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.6.0\n",
      "  Using cached tensorflow-2.6.0-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n",
      "Requirement already satisfied: keras~=2.6 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (1.1.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (0.2.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (0.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (1.12.1)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (2.8.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (0.37.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (1.6.3)\n",
      "Requirement already satisfied: clang~=5.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (1.46.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (1.1.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (1.19.5)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (0.4.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (3.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (2.8.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow==2.6.0) (3.20.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.6.0) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.1.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.6.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (45.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.6.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/rakiiibul/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (4.11.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/rakiiibul/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/rakiiibul/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/rakiiibul/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (3.8.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/rakiiibul/.local/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (3.1.0)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model interface\n",
    "from IPython.core.events import post_execute\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second: 23.976023976023978\n",
      "Frame count: 2486\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def point():\n",
    "    x = [\n",
    "        'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22',\n",
    "        'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'x31', 'x32', 'x33',\n",
    "    ]\n",
    "    y = [\n",
    "        'y12', 'y13', 'y14', 'y15', 'y16', 'y17', 'y18', 'y19', 'y20', 'y21', 'y22',\n",
    "        'y23', 'y24', 'y25', 'y26', 'y27', 'y28', 'y29', 'y30', 'y31', 'y32', 'y33',\n",
    "    ]\n",
    "    z = [\n",
    "        'z12', 'z13', 'z14', 'z15', 'z16', 'z17', 'z18', 'z19', 'z20', 'z21', 'z22',\n",
    "        'z23', 'z24', 'z25', 'z26', 'z27', 'z28', 'z29', 'z30', 'z31', 'z32', 'z33',\n",
    "    ]\n",
    "    v = [\n",
    "        'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21', 'v22',\n",
    "        'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'v29', 'v30', 'v31', 'v32', 'v33',\n",
    "    ]\n",
    "    coords = [x, y, z, v]\n",
    "    return coords\n",
    "\n",
    "def display_tflite_classify_pose(cap, model):\n",
    "    if (cap.isOpened() == False):\n",
    "        print(\"Error opening the video file.\")\n",
    "    else:\n",
    "        input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(f'Frames per second: {input_fps}')\n",
    "        print(f'Frame count: {frame_count}')\n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils # Drawing helpers.\n",
    "    mp_holistic = mp.solutions.holistic     # Mediapipe Solutions.\n",
    "\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False    \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Pose Detections\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                        )\n",
    "                # Export coordinates\n",
    "                try:\n",
    "                    # Extract Pose landmarks\n",
    "                    pose = results.pose_landmarks.landmark\n",
    "                    pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "                    # Concate rows\n",
    "                    row = pose_row\n",
    "                    # print(f'type: {type(row)}, \\n{row}')\n",
    "\n",
    "                    # point[11] - point[32] input to tflite model.\n",
    "                    coords = point()\n",
    "                    specify_float = 8\n",
    "\n",
    "                    dict_p12_to_p33 = {\n",
    "                        # x12 to x33\n",
    "                        coords[0][0]:round(row[44], specify_float),\n",
    "                        coords[0][1]:round(row[48], specify_float),\n",
    "                        coords[0][2]:round(row[52], specify_float),\n",
    "                        coords[0][3]:round(row[56], specify_float),\n",
    "                        coords[0][4]:round(row[60], specify_float),\n",
    "                        coords[0][5]:round(row[64], specify_float),\n",
    "                        coords[0][6]:round(row[68], specify_float),\n",
    "                        coords[0][7]:round(row[72], specify_float),\n",
    "                        coords[0][8]:round(row[76], specify_float),\n",
    "                        coords[0][9]:round(row[80], specify_float),\n",
    "                        coords[0][10]:round(row[84], specify_float),\n",
    "                        coords[0][11]:round(row[88], specify_float),\n",
    "                        coords[0][12]:round(row[92], specify_float),\n",
    "                        coords[0][13]:round(row[96], specify_float),\n",
    "                        coords[0][14]:round(row[100], specify_float),\n",
    "                        coords[0][15]:round(row[104], specify_float),\n",
    "                        coords[0][16]:round(row[108], specify_float),\n",
    "                        coords[0][17]:round(row[112], specify_float),\n",
    "                        coords[0][18]:round(row[116], specify_float),\n",
    "                        coords[0][19]:round(row[120], specify_float),\n",
    "                        coords[0][20]:round(row[124], specify_float),\n",
    "                        coords[0][21]:round(row[128], specify_float),\n",
    "\n",
    "                        # y12 to y33\n",
    "                        coords[1][0]:round(row[45], specify_float),\n",
    "                        coords[1][1]:round(row[49], specify_float),\n",
    "                        coords[1][2]:round(row[53], specify_float),\n",
    "                        coords[1][3]:round(row[57], specify_float),\n",
    "                        coords[1][4]:round(row[61], specify_float),\n",
    "                        coords[1][5]:round(row[65], specify_float),\n",
    "                        coords[1][6]:round(row[69], specify_float),\n",
    "                        coords[1][7]:round(row[73], specify_float),\n",
    "                        coords[1][8]:round(row[77], specify_float),\n",
    "                        coords[1][9]:round(row[81], specify_float),\n",
    "                        coords[1][10]:round(row[85], specify_float),\n",
    "                        coords[1][11]:round(row[89], specify_float),\n",
    "                        coords[1][12]:round(row[93], specify_float),\n",
    "                        coords[1][13]:round(row[97], specify_float),\n",
    "                        coords[1][14]:round(row[101], specify_float),\n",
    "                        coords[1][15]:round(row[105], specify_float),\n",
    "                        coords[1][16]:round(row[109], specify_float),\n",
    "                        coords[1][17]:round(row[113], specify_float),\n",
    "                        coords[1][18]:round(row[117], specify_float),\n",
    "                        coords[1][19]:round(row[121], specify_float),\n",
    "                        coords[1][20]:round(row[125], specify_float),\n",
    "                        coords[1][21]:round(row[129], specify_float),\n",
    "\n",
    "                        # z12 to z33\n",
    "                        coords[2][0]:round(row[46], specify_float),\n",
    "                        coords[2][1]:round(row[50], specify_float),\n",
    "                        coords[2][2]:round(row[54], specify_float),\n",
    "                        coords[2][3]:round(row[58], specify_float),\n",
    "                        coords[2][4]:round(row[62], specify_float),\n",
    "                        coords[2][5]:round(row[66], specify_float),\n",
    "                        coords[2][6]:round(row[70], specify_float),\n",
    "                        coords[2][7]:round(row[74], specify_float),\n",
    "                        coords[2][8]:round(row[78], specify_float),\n",
    "                        coords[2][9]:round(row[82], specify_float),\n",
    "                        coords[2][10]:round(row[86], specify_float),\n",
    "                        coords[2][11]:round(row[90], specify_float),\n",
    "                        coords[2][12]:round(row[94], specify_float),\n",
    "                        coords[2][13]:round(row[98], specify_float),\n",
    "                        coords[2][14]:round(row[102], specify_float),\n",
    "                        coords[2][15]:round(row[106], specify_float),\n",
    "                        coords[2][16]:round(row[110], specify_float),\n",
    "                        coords[2][17]:round(row[114], specify_float),\n",
    "                        coords[2][18]:round(row[118], specify_float),\n",
    "                        coords[2][19]:round(row[122], specify_float),\n",
    "                        coords[2][20]:round(row[126], specify_float),\n",
    "                        coords[2][21]:round(row[130], specify_float),\n",
    "\n",
    "                        # v12 to v33\n",
    "                        coords[3][0]:round(row[47], specify_float),\n",
    "                        coords[3][1]:round(row[51], specify_float),\n",
    "                        coords[3][2]:round(row[55], specify_float),\n",
    "                        coords[3][3]:round(row[59], specify_float),\n",
    "                        coords[3][4]:round(row[63], specify_float),\n",
    "                        coords[3][5]:round(row[67], specify_float),\n",
    "                        coords[3][6]:round(row[71], specify_float),\n",
    "                        coords[3][7]:round(row[75], specify_float),\n",
    "                        coords[3][8]:round(row[79], specify_float),\n",
    "                        coords[3][9]:round(row[83], specify_float),\n",
    "                        coords[3][10]:round(row[87], specify_float),\n",
    "                        coords[3][11]:round(row[91], specify_float),\n",
    "                        coords[3][12]:round(row[95], specify_float),\n",
    "                        coords[3][13]:round(row[99], specify_float),\n",
    "                        coords[3][14]:round(row[103], specify_float),\n",
    "                        coords[3][15]:round(row[107], specify_float),\n",
    "                        coords[3][16]:round(row[111], specify_float),\n",
    "                        coords[3][17]:round(row[115], specify_float),\n",
    "                        coords[3][18]:round(row[119], specify_float),\n",
    "                        coords[3][19]:round(row[123], specify_float),\n",
    "                        coords[3][20]:round(row[127], specify_float),\n",
    "                        coords[3][21]:round(row[131], specify_float),\n",
    "                    }\n",
    "                    input_dict = {name: np.expand_dims(np.array(value, dtype=np.float32), axis=0) for name, value in dict_p12_to_p33.items()}\n",
    "                    \n",
    "                    # Make Detections\n",
    "                    # 0: cat_camel, 1: bridge_exercise, 2: heel_raise.\n",
    "                    result = tflite_inference(input=input_dict, model=model)\n",
    "                    body_language_class = np.argmax(result)\n",
    "                    # body_language_prob = round(result[np.argmax(result)], 2)*100\n",
    "                    body_language_prob = result[np.argmax(result)]\n",
    "\n",
    "                    if str(body_language_class) == '0':\n",
    "                        pose_class = 'Cat camel' \n",
    "                    elif str(body_language_class) == '1':\n",
    "                        pose_class = 'Bridge exercise'\n",
    "                    else:\n",
    "                        pose_class = 'Heel raise'\n",
    "                    \n",
    "                    # print(f'calss: {body_language_class}, prob: {body_language_prob}')\n",
    "\n",
    "                    # Show pose category near the ear.\n",
    "                    coords = tuple(np.multiply(\n",
    "                        np.array(\n",
    "                            (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                            results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)),\n",
    "                        [1280,480]\n",
    "                    ).astype(int))\n",
    "\n",
    "                    # cv2.rectangle(影像, 頂點座標, 對向頂點座標, 顏色, 線條寬度).\n",
    "                    # cv2.putText(影像, 文字, 座標, 字型, 大小, 顏色, 線條寬度, 線條種類).\n",
    "                    cv2.rectangle(image, \n",
    "                                (coords[0], coords[1]+5), \n",
    "                                (coords[0]+200, coords[1]-30), \n",
    "                                (245, 117, 16), -1)\n",
    "                    cv2.putText(image, pose_class, coords, \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                    # Get status box\n",
    "                    cv2.rectangle(image, (10,0), (310, 55), (0, 0, 0), -1)\n",
    "\n",
    "                    # Display Class\n",
    "                    cv2.putText(\n",
    "                        image, \n",
    "                        'CLASS: ', (15, 25), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.9, (255, 255, 0), 1, cv2.LINE_AA\n",
    "                    )\n",
    "                    cv2.putText(\n",
    "                        image, \n",
    "                        pose_class, (120, 25), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                    )\n",
    "\n",
    "                    # Display Probability\n",
    "                    cv2.putText(\n",
    "                        image, \n",
    "                        'PROB: ', (15, 50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.9, (255, 255, 0), 1, cv2.LINE_AA\n",
    "                    )\n",
    "                    cv2.putText(\n",
    "                        image, \n",
    "                        str(body_language_prob), (120, 50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                    )\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print('Done!')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def save_tflite_classify_pose(cap, model, result_out):\n",
    "    if (cap.isOpened() == False):\n",
    "        print(\"Error opening the video file.\")\n",
    "    else:\n",
    "        input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        output_fps = input_fps - 1\n",
    "        print(f'Frames per second: {input_fps}')\n",
    "        print(f'Frame count: {frame_count}')\n",
    "\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f'video_w: {w}, video_h: {h}')\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # 輸出附檔名為 mp4. \n",
    "    out = cv2.VideoWriter(result_out, fourcc, output_fps, (w, h))\n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils # Drawing helpers.\n",
    "    mp_holistic = mp.solutions.holistic     # Mediapipe Solutions.\n",
    "\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False    \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Pose Detections\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                        )\n",
    "                # Export coordinates\n",
    "                try:\n",
    "                    # Extract Pose landmarks\n",
    "                    pose = results.pose_landmarks.landmark\n",
    "                    pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "                    # Concate rows\n",
    "                    row = pose_row\n",
    "                    # print(f'type: {type(row)}, \\n{row}')\n",
    "\n",
    "                    # point[11] - point[32] input to tflite model.\n",
    "                    coords = point()\n",
    "                    specify_float = 8\n",
    "\n",
    "                    dict_p12_to_p33 = {\n",
    "                        # x12 to x33\n",
    "                        coords[0][0]:round(row[44], specify_float),\n",
    "                        coords[0][1]:round(row[48], specify_float),\n",
    "                        coords[0][2]:round(row[52], specify_float),\n",
    "                        coords[0][3]:round(row[56], specify_float),\n",
    "                        coords[0][4]:round(row[60], specify_float),\n",
    "                        coords[0][5]:round(row[64], specify_float),\n",
    "                        coords[0][6]:round(row[68], specify_float),\n",
    "                        coords[0][7]:round(row[72], specify_float),\n",
    "                        coords[0][8]:round(row[76], specify_float),\n",
    "                        coords[0][9]:round(row[80], specify_float),\n",
    "                        coords[0][10]:round(row[84], specify_float),\n",
    "                        coords[0][11]:round(row[88], specify_float),\n",
    "                        coords[0][12]:round(row[92], specify_float),\n",
    "                        coords[0][13]:round(row[96], specify_float),\n",
    "                        coords[0][14]:round(row[100], specify_float),\n",
    "                        coords[0][15]:round(row[104], specify_float),\n",
    "                        coords[0][16]:round(row[108], specify_float),\n",
    "                        coords[0][17]:round(row[112], specify_float),\n",
    "                        coords[0][18]:round(row[116], specify_float),\n",
    "                        coords[0][19]:round(row[120], specify_float),\n",
    "                        coords[0][20]:round(row[124], specify_float),\n",
    "                        coords[0][21]:round(row[128], specify_float),\n",
    "\n",
    "                        # y12 to y33\n",
    "                        coords[1][0]:round(row[45], specify_float),\n",
    "                        coords[1][1]:round(row[49], specify_float),\n",
    "                        coords[1][2]:round(row[53], specify_float),\n",
    "                        coords[1][3]:round(row[57], specify_float),\n",
    "                        coords[1][4]:round(row[61], specify_float),\n",
    "                        coords[1][5]:round(row[65], specify_float),\n",
    "                        coords[1][6]:round(row[69], specify_float),\n",
    "                        coords[1][7]:round(row[73], specify_float),\n",
    "                        coords[1][8]:round(row[77], specify_float),\n",
    "                        coords[1][9]:round(row[81], specify_float),\n",
    "                        coords[1][10]:round(row[85], specify_float),\n",
    "                        coords[1][11]:round(row[89], specify_float),\n",
    "                        coords[1][12]:round(row[93], specify_float),\n",
    "                        coords[1][13]:round(row[97], specify_float),\n",
    "                        coords[1][14]:round(row[101], specify_float),\n",
    "                        coords[1][15]:round(row[105], specify_float),\n",
    "                        coords[1][16]:round(row[109], specify_float),\n",
    "                        coords[1][17]:round(row[113], specify_float),\n",
    "                        coords[1][18]:round(row[117], specify_float),\n",
    "                        coords[1][19]:round(row[121], specify_float),\n",
    "                        coords[1][20]:round(row[125], specify_float),\n",
    "                        coords[1][21]:round(row[129], specify_float),\n",
    "\n",
    "                        # z12 to z33\n",
    "                        coords[2][0]:round(row[46], specify_float),\n",
    "                        coords[2][1]:round(row[50], specify_float),\n",
    "                        coords[2][2]:round(row[54], specify_float),\n",
    "                        coords[2][3]:round(row[58], specify_float),\n",
    "                        coords[2][4]:round(row[62], specify_float),\n",
    "                        coords[2][5]:round(row[66], specify_float),\n",
    "                        coords[2][6]:round(row[70], specify_float),\n",
    "                        coords[2][7]:round(row[74], specify_float),\n",
    "                        coords[2][8]:round(row[78], specify_float),\n",
    "                        coords[2][9]:round(row[82], specify_float),\n",
    "                        coords[2][10]:round(row[86], specify_float),\n",
    "                        coords[2][11]:round(row[90], specify_float),\n",
    "                        coords[2][12]:round(row[94], specify_float),\n",
    "                        coords[2][13]:round(row[98], specify_float),\n",
    "                        coords[2][14]:round(row[102], specify_float),\n",
    "                        coords[2][15]:round(row[106], specify_float),\n",
    "                        coords[2][16]:round(row[110], specify_float),\n",
    "                        coords[2][17]:round(row[114], specify_float),\n",
    "                        coords[2][18]:round(row[118], specify_float),\n",
    "                        coords[2][19]:round(row[122], specify_float),\n",
    "                        coords[2][20]:round(row[126], specify_float),\n",
    "                        coords[2][21]:round(row[130], specify_float),\n",
    "\n",
    "                        # v12 to v33\n",
    "                        coords[3][0]:round(row[47], specify_float),\n",
    "                        coords[3][1]:round(row[51], specify_float),\n",
    "                        coords[3][2]:round(row[55], specify_float),\n",
    "                        coords[3][3]:round(row[59], specify_float),\n",
    "                        coords[3][4]:round(row[63], specify_float),\n",
    "                        coords[3][5]:round(row[67], specify_float),\n",
    "                        coords[3][6]:round(row[71], specify_float),\n",
    "                        coords[3][7]:round(row[75], specify_float),\n",
    "                        coords[3][8]:round(row[79], specify_float),\n",
    "                        coords[3][9]:round(row[83], specify_float),\n",
    "                        coords[3][10]:round(row[87], specify_float),\n",
    "                        coords[3][11]:round(row[91], specify_float),\n",
    "                        coords[3][12]:round(row[95], specify_float),\n",
    "                        coords[3][13]:round(row[99], specify_float),\n",
    "                        coords[3][14]:round(row[103], specify_float),\n",
    "                        coords[3][15]:round(row[107], specify_float),\n",
    "                        coords[3][16]:round(row[111], specify_float),\n",
    "                        coords[3][17]:round(row[115], specify_float),\n",
    "                        coords[3][18]:round(row[119], specify_float),\n",
    "                        coords[3][19]:round(row[123], specify_float),\n",
    "                        coords[3][20]:round(row[127], specify_float),\n",
    "                        coords[3][21]:round(row[131], specify_float),\n",
    "                    }\n",
    "                    input_dict = {name: np.expand_dims(np.array(value, dtype=np.float32), axis=0) for name, value in dict_p12_to_p33.items()}\n",
    "                    \n",
    "                    # Make Detections\n",
    "                    # 0: cat_camel, 1: bridge_exercise, 2: heel_raise.\n",
    "                    result = tflite_inference(input=input_dict, model=model)\n",
    "                    body_language_class = np.argmax(result)\n",
    "                    # body_language_prob = round(result[np.argmax(result)], 2)*100\n",
    "                    body_language_prob = result[np.argmax(result)]\n",
    "\n",
    "                    if str(body_language_class) == '0':\n",
    "                        pose_class = 'Cat camel' \n",
    "                    elif str(body_language_class) == '1':\n",
    "                        pose_class = 'Bridge exercise'\n",
    "                    else:\n",
    "                        pose_class = 'Heel raise'\n",
    "                    \n",
    "                    # print(f'calss: {body_language_class}, prob: {body_language_prob}')\n",
    "\n",
    "                    # Show pose category near the ear.\n",
    "                    coords = tuple(np.multiply(\n",
    "                        np.array(\n",
    "                            (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                            results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)),\n",
    "                        [1280,480]\n",
    "                    ).astype(int))\n",
    "\n",
    "                    # cv2.rectangle(影像, 頂點座標, 對向頂點座標, 顏色, 線條寬度).\n",
    "                    # cv2.putText(影像, 文字, 座標, 字型, 大小, 顏色, 線條寬度, 線條種類).\n",
    "                    cv2.rectangle(image, \n",
    "                                (coords[0], coords[1]+5), \n",
    "                                (coords[0]+200, coords[1]-30), \n",
    "                                (245, 117, 16), -1)\n",
    "                    cv2.putText(image, pose_class, coords, \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                    # Get status box\n",
    "                    cv2.rectangle(image, (10,0), (310, 55), (0, 0, 0), -1)\n",
    "\n",
    "                    # Display Class\n",
    "                    cv2.putText(\n",
    "                        image, \n",
    "                        'CLASS: ', (15, 25), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.9, (255, 255, 0), 1, cv2.LINE_AA\n",
    "                    )\n",
    "                    cv2.putText(\n",
    "                        image, \n",
    "                        pose_class, (120, 25), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                    )\n",
    "\n",
    "                    # Display Probability\n",
    "                    cv2.putText(\n",
    "                        image, \n",
    "                        'PROB: ', (15, 50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.9, (255, 255, 0), 1, cv2.LINE_AA\n",
    "                    )\n",
    "                    cv2.putText(\n",
    "                        image, \n",
    "                        str(body_language_prob), (120, 50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                    )\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                out.write(image)\n",
    "                cv2.imshow('Pose classification result', image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print('Save done!')\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def sample1_xyz(file):\n",
    "    df = test_data_xyz(file)\n",
    "    # print(f'df: \\n{df}')\n",
    "    \n",
    "    coords = point()\n",
    "    specify_float = 8\n",
    "    print(round(df.iat[0, 66], specify_float))\n",
    "    # bb=df['z33']\n",
    "    # print(f'z33: {bb}')\n",
    "    \n",
    "    sample = {\n",
    "        # x12 to x33\n",
    "        coords[0][0]:round(df.iat[0, 1], specify_float),\n",
    "        coords[0][1]:round(df.iat[0, 4], specify_float),\n",
    "        coords[0][2]:round(df.iat[0, 7], specify_float),\n",
    "        coords[0][3]:round(df.iat[0, 10], specify_float),\n",
    "        coords[0][4]:round(df.iat[0, 13], specify_float),\n",
    "        coords[0][5]:round(df.iat[0, 16], specify_float),\n",
    "        coords[0][6]:round(df.iat[0, 19], specify_float),\n",
    "        coords[0][7]:round(df.iat[0, 22], specify_float),\n",
    "        coords[0][8]:round(df.iat[0, 25], specify_float),\n",
    "        coords[0][9]:round(df.iat[0, 28], specify_float),\n",
    "        coords[0][10]:round(df.iat[0, 31], specify_float),\n",
    "        coords[0][11]:round(df.iat[0, 34], specify_float),\n",
    "        coords[0][12]:round(df.iat[0, 37], specify_float),\n",
    "        coords[0][13]:round(df.iat[0, 40], specify_float),\n",
    "        coords[0][14]:round(df.iat[0, 43], specify_float),\n",
    "        coords[0][15]:round(df.iat[0, 46], specify_float),\n",
    "        coords[0][16]:round(df.iat[0, 49], specify_float),\n",
    "        coords[0][17]:round(df.iat[0, 52], specify_float),\n",
    "        coords[0][18]:round(df.iat[0, 55], specify_float),\n",
    "        coords[0][19]:round(df.iat[0, 58], specify_float),\n",
    "        coords[0][20]:round(df.iat[0, 61], specify_float),\n",
    "        coords[0][21]:round(df.iat[0, 64], specify_float),\n",
    "\n",
    "        # y12 to y33\n",
    "        coords[1][0]:round(df.iat[0, 2], specify_float),\n",
    "        coords[1][1]:round(df.iat[0, 5], specify_float),\n",
    "        coords[1][2]:round(df.iat[0, 8], specify_float),\n",
    "        coords[1][3]:round(df.iat[0, 11], specify_float),\n",
    "        coords[1][4]:round(df.iat[0, 14], specify_float),\n",
    "        coords[1][5]:round(df.iat[0, 17], specify_float),\n",
    "        coords[1][6]:round(df.iat[0, 20], specify_float),\n",
    "        coords[1][7]:round(df.iat[0, 23], specify_float),\n",
    "        coords[1][8]:round(df.iat[0, 26], specify_float),\n",
    "        coords[1][9]:round(df.iat[0, 39], specify_float),\n",
    "        coords[1][10]:round(df.iat[0, 32], specify_float),\n",
    "        coords[1][11]:round(df.iat[0, 35], specify_float),\n",
    "        coords[1][12]:round(df.iat[0, 38], specify_float),\n",
    "        coords[1][13]:round(df.iat[0, 41], specify_float),\n",
    "        coords[1][14]:round(df.iat[0, 44], specify_float),\n",
    "        coords[1][15]:round(df.iat[0, 47], specify_float),\n",
    "        coords[1][16]:round(df.iat[0, 50], specify_float),\n",
    "        coords[1][17]:round(df.iat[0, 53], specify_float),\n",
    "        coords[1][18]:round(df.iat[0, 56], specify_float),\n",
    "        coords[1][19]:round(df.iat[0, 59], specify_float),\n",
    "        coords[1][20]:round(df.iat[0, 62], specify_float),\n",
    "        coords[1][21]:round(df.iat[0, 65], specify_float),\n",
    "\n",
    "        # z12 to z33\n",
    "        coords[2][0]:round(df.iat[0, 3], specify_float),\n",
    "        coords[2][1]:round(df.iat[0, 6], specify_float),\n",
    "        coords[2][2]:round(df.iat[0, 9], specify_float),\n",
    "        coords[2][3]:round(df.iat[0, 12], specify_float),\n",
    "        coords[2][4]:round(df.iat[0, 15], specify_float),\n",
    "        coords[2][5]:round(df.iat[0, 18], specify_float),\n",
    "        coords[2][6]:round(df.iat[0, 21], specify_float),\n",
    "        coords[2][7]:round(df.iat[0, 24], specify_float),\n",
    "        coords[2][8]:round(df.iat[0, 27], specify_float),\n",
    "        coords[2][9]:round(df.iat[0, 30], specify_float),\n",
    "        coords[2][10]:round(df.iat[0, 33], specify_float),\n",
    "        coords[2][11]:round(df.iat[0, 36], specify_float),\n",
    "        coords[2][12]:round(df.iat[0, 39], specify_float),\n",
    "        coords[2][13]:round(df.iat[0, 42], specify_float),\n",
    "        coords[2][14]:round(df.iat[0, 45], specify_float),\n",
    "        coords[2][15]:round(df.iat[0, 48], specify_float),\n",
    "        coords[2][16]:round(df.iat[0, 51], specify_float),\n",
    "        coords[2][17]:round(df.iat[0, 54], specify_float),\n",
    "        coords[2][18]:round(df.iat[0, 57], specify_float),\n",
    "        coords[2][19]:round(df.iat[0, 60], specify_float),\n",
    "        coords[2][20]:round(df.iat[0, 63], specify_float),\n",
    "        coords[2][21]:round(df.iat[0, 66], specify_float),\n",
    "    }\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "def sample2_xyzv(file):\n",
    "    df = test_data_xyzv(file)\n",
    "    # print(f'df: \\n{df}')\n",
    "    \n",
    "    coords = point()\n",
    "    specify_float = 8\n",
    "    \n",
    "    sample = {\n",
    "        # x12 to x33\n",
    "        coords[0][0]:round(df.iat[0, 1], specify_float),\n",
    "        coords[0][1]:round(df.iat[0, 5], specify_float),\n",
    "        coords[0][2]:round(df.iat[0, 9], specify_float),\n",
    "        coords[0][3]:round(df.iat[0, 13], specify_float),\n",
    "        coords[0][4]:round(df.iat[0, 17], specify_float),\n",
    "        coords[0][5]:round(df.iat[0, 21], specify_float),\n",
    "        coords[0][6]:round(df.iat[0, 25], specify_float),\n",
    "        coords[0][7]:round(df.iat[0, 29], specify_float),\n",
    "        coords[0][8]:round(df.iat[0, 33], specify_float),\n",
    "        coords[0][9]:round(df.iat[0, 37], specify_float),\n",
    "        coords[0][10]:round(df.iat[0, 41], specify_float),\n",
    "        coords[0][11]:round(df.iat[0, 45], specify_float),\n",
    "        coords[0][12]:round(df.iat[0, 49], specify_float),\n",
    "        coords[0][13]:round(df.iat[0, 53], specify_float),\n",
    "        coords[0][14]:round(df.iat[0, 57], specify_float),\n",
    "        coords[0][15]:round(df.iat[0, 61], specify_float),\n",
    "        coords[0][16]:round(df.iat[0, 65], specify_float),\n",
    "        coords[0][17]:round(df.iat[0, 69], specify_float),\n",
    "        coords[0][18]:round(df.iat[0, 73], specify_float),\n",
    "        coords[0][19]:round(df.iat[0, 77], specify_float),\n",
    "        coords[0][20]:round(df.iat[0, 81], specify_float),\n",
    "        coords[0][21]:round(df.iat[0, 85], specify_float),\n",
    "\n",
    "        # y12 to y33\n",
    "        coords[1][0]:round(df.iat[0, 2], specify_float),\n",
    "        coords[1][1]:round(df.iat[0, 6], specify_float),\n",
    "        coords[1][2]:round(df.iat[0, 10], specify_float),\n",
    "        coords[1][3]:round(df.iat[0, 14], specify_float),\n",
    "        coords[1][4]:round(df.iat[0, 18], specify_float),\n",
    "        coords[1][5]:round(df.iat[0, 22], specify_float),\n",
    "        coords[1][6]:round(df.iat[0, 26], specify_float),\n",
    "        coords[1][7]:round(df.iat[0, 30], specify_float),\n",
    "        coords[1][8]:round(df.iat[0, 34], specify_float),\n",
    "        coords[1][9]:round(df.iat[0, 38], specify_float),\n",
    "        coords[1][10]:round(df.iat[0, 42], specify_float),\n",
    "        coords[1][11]:round(df.iat[0, 46], specify_float),\n",
    "        coords[1][12]:round(df.iat[0, 50], specify_float),\n",
    "        coords[1][13]:round(df.iat[0, 51], specify_float),\n",
    "        coords[1][14]:round(df.iat[0, 58], specify_float),\n",
    "        coords[1][15]:round(df.iat[0, 62], specify_float),\n",
    "        coords[1][16]:round(df.iat[0, 66], specify_float),\n",
    "        coords[1][17]:round(df.iat[0, 70], specify_float),\n",
    "        coords[1][18]:round(df.iat[0, 74], specify_float),\n",
    "        coords[1][19]:round(df.iat[0, 78], specify_float),\n",
    "        coords[1][20]:round(df.iat[0, 82], specify_float),\n",
    "        coords[1][21]:round(df.iat[0, 86], specify_float),\n",
    "\n",
    "        # z12 to z33\n",
    "        coords[2][0]:round(df.iat[0, 3], specify_float),\n",
    "        coords[2][1]:round(df.iat[0, 7], specify_float),\n",
    "        coords[2][2]:round(df.iat[0, 11], specify_float),\n",
    "        coords[2][3]:round(df.iat[0, 15], specify_float),\n",
    "        coords[2][4]:round(df.iat[0, 19], specify_float),\n",
    "        coords[2][5]:round(df.iat[0, 23], specify_float),\n",
    "        coords[2][6]:round(df.iat[0, 27], specify_float),\n",
    "        coords[2][7]:round(df.iat[0, 31], specify_float),\n",
    "        coords[2][8]:round(df.iat[0, 35], specify_float),\n",
    "        coords[2][9]:round(df.iat[0, 39], specify_float),\n",
    "        coords[2][10]:round(df.iat[0, 43], specify_float),\n",
    "        coords[2][11]:round(df.iat[0, 47], specify_float),\n",
    "        coords[2][12]:round(df.iat[0, 51], specify_float),\n",
    "        coords[2][13]:round(df.iat[0, 55], specify_float),\n",
    "        coords[2][14]:round(df.iat[0, 59], specify_float),\n",
    "        coords[2][15]:round(df.iat[0, 63], specify_float),\n",
    "        coords[2][16]:round(df.iat[0, 67], specify_float),\n",
    "        coords[2][17]:round(df.iat[0, 71], specify_float),\n",
    "        coords[2][18]:round(df.iat[0, 75], specify_float),\n",
    "        coords[2][19]:round(df.iat[0, 79], specify_float),\n",
    "        coords[2][20]:round(df.iat[0, 83], specify_float),\n",
    "        coords[2][21]:round(df.iat[0, 87], specify_float),\n",
    "\n",
    "        # v12 to v33\n",
    "        coords[3][0]:round(df.iat[0, 4], specify_float),\n",
    "        coords[3][1]:round(df.iat[0, 8], specify_float),\n",
    "        coords[3][2]:round(df.iat[0, 12], specify_float),\n",
    "        coords[3][3]:round(df.iat[0, 16], specify_float),\n",
    "        coords[3][4]:round(df.iat[0, 20], specify_float),\n",
    "        coords[3][5]:round(df.iat[0, 24], specify_float),\n",
    "        coords[3][6]:round(df.iat[0, 28], specify_float),\n",
    "        coords[3][7]:round(df.iat[0, 32], specify_float),\n",
    "        coords[3][8]:round(df.iat[0, 36], specify_float),\n",
    "        coords[3][9]:round(df.iat[0, 40], specify_float),\n",
    "        coords[3][10]:round(df.iat[0, 44], specify_float),\n",
    "        coords[3][11]:round(df.iat[0, 48], specify_float),\n",
    "        coords[3][12]:round(df.iat[0, 52], specify_float),\n",
    "        coords[3][13]:round(df.iat[0, 56], specify_float),\n",
    "        coords[3][14]:round(df.iat[0, 60], specify_float),\n",
    "        coords[3][15]:round(df.iat[0, 64], specify_float),\n",
    "        coords[3][16]:round(df.iat[0, 68], specify_float),\n",
    "        coords[3][17]:round(df.iat[0, 72], specify_float),\n",
    "        coords[3][18]:round(df.iat[0, 76], specify_float),\n",
    "        coords[3][19]:round(df.iat[0, 80], specify_float),\n",
    "        coords[3][20]:round(df.iat[0, 84], specify_float),\n",
    "        coords[3][21]:round(df.iat[0, 88], specify_float),\n",
    "    }\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "def test_data_xyz(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df2 = df.copy()\n",
    "\n",
    "    columns_removed = [\n",
    "        'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11',\n",
    "        'y1', 'y2', 'y3', 'y4', 'y5', 'y6', 'y7', 'y8', 'y9', 'y10', 'y11',\n",
    "        'z1', 'z2', 'z3', 'z4', 'z5', 'z6', 'z7', 'z8', 'z9', 'z10', 'z11',\n",
    "        'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11',\n",
    "\n",
    "        'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21',\n",
    "        'v22', 'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'v29', 'v30', 'v31',\n",
    "        'v32', 'v33',\n",
    "    ]\n",
    "\n",
    "    df2 = df2.drop(columns_removed, axis = 'columns')\n",
    "\n",
    "    # Get A row from A to B.\n",
    "    get_a_row_value = df2.iloc[4:5]\n",
    "    return get_a_row_value\n",
    "\n",
    "\n",
    "def test_data_xyzv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df2 = df.copy()\n",
    "\n",
    "    columns_removed = [\n",
    "        'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11',\n",
    "        'y1', 'y2', 'y3', 'y4', 'y5', 'y6', 'y7', 'y8', 'y9', 'y10', 'y11',\n",
    "        'z1', 'z2', 'z3', 'z4', 'z5', 'z6', 'z7', 'z8', 'z9', 'z10', 'z11',\n",
    "        'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11',\n",
    "    ]\n",
    "\n",
    "    df2 = df2.drop(columns_removed, axis = 'columns')\n",
    "\n",
    "    # Get row from 4 to 5.\n",
    "    get_a_row_value = df2.iloc[4:5]\n",
    "    return get_a_row_value\n",
    "\n",
    "\n",
    "def desktop_model_inference(input, model):\n",
    "    '''# Loads the model and training weights for desktop model and test inference.'''\n",
    "\n",
    "    model = keras.models.load_model(model)\n",
    "    # print(model.summary())\n",
    "\n",
    "    # print(f'input: \\n{type(input)}')\n",
    "    outputs = model.predict(input)\n",
    "\n",
    "    # print('*'*30) \n",
    "    # print(f'tatal: {outputs[0][0] + outputs[0][1] + outputs[0][2]}')\n",
    "    # print(f'calss: {np.argmax(outputs[0])}, prob: {outputs[0][np.argmax(outputs[0])]}')\n",
    "    # print(f'calss: {np.argmax(outputs[0])}, prob: {round(outputs[0][np.argmax(outputs[0])]*100, 5)}%')\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def tflite_inference(input, model):\n",
    "    # Load TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    ### Get input and output tensors. ###\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # tf.print('input_details[0]:\\n', input_details[0])\n",
    "    # tf.print('output_details:\\n', output_details)\n",
    "    # print('-'*30)\n",
    "    # print(f'input_index: {input_details[0][\"index\"]}')\n",
    "    # print(f'output_index: {output_details[0][\"index\"]}')\n",
    "    # print(f'input_shape: {input_details[0][\"shape\"]}')\n",
    "    # print('-'*30)\n",
    "\n",
    "    ### Verify the TensorFlow Lite model. ###\n",
    "    for i, (name, value) in enumerate(input.items()):\n",
    "\n",
    "        input_value = np.expand_dims(value, axis=1)\n",
    "        # print(f'index: {i}, type: {type(input_value)}, shape:{input_value.shape}')\n",
    "        # print(input_value)\n",
    "        interpreter.set_tensor(input_details[i]['index'], input_value)\n",
    "        interpreter.invoke()\n",
    "\n",
    "    output = interpreter.tensor(output_details[0]['index'])()[0]\n",
    "\n",
    "    # print(f'prob: {output}, type: {type(output)}')\n",
    "    # print(f'calss: {np.argmax(output)}, prob: {output[np.argmax(output)]}')\n",
    "    return output\n",
    "\n",
    "\n",
    "def test_model_inference(input_csv, pc_model, tflite_model):\n",
    "    '''Input a row data(point12 to point33 features) to desktop model and tflite model from test csv file for inference.'''\n",
    "    test_input_xyzv = sample2_xyzv(file=input_csv)\n",
    "    input_dict = {name: np.expand_dims(np.array(value, dtype=np.float32), axis=0) for name, value in test_input_xyzv.items()}\n",
    "\n",
    "    result_pc_model = desktop_model_inference(input=input_dict, model=pc_model)\n",
    "    result_tflite = tflite_inference(input=input_dict, model=tflite_model)\n",
    "\n",
    "    print('-'*30)\n",
    "    print(f'[Desktop model inference]\\nprob: {result_pc_model}, type: {type(result_pc_model)}')\n",
    "    print(f'calss: {np.argmax(result_pc_model[0])}, prob: {result_pc_model[0][np.argmax(result_pc_model[0])]}')\n",
    "    print('-'*30)\n",
    "    print(f'[TFLite model inference]\\nprob: {result_tflite}, type: {type(result_tflite)}')\n",
    "    print(f'calss: {np.argmax(result_tflite)}, prob: {result_tflite[np.argmax(result_tflite)]}')\n",
    "    print('-'*30)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # 0: cat_camel, 1: bridge_exercise, 2: heel_raise\n",
    "    video_file_name = 'cat_camel' + '3'\n",
    "    output_video = './' + video_file_name + 'my_out.mp4'\n",
    "    video_path = ''+ video_file_name + '.mp4'\n",
    "    \n",
    "    test_file = './datasets/numerical_coords_dataset_test2.csv'\n",
    "    all_model = './model_weights/all_model/08.31_xyzv/3_categories_pose'\n",
    "    tflite_model = 'model.tflite'\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # test_model_inference(input_csv=test_file, pc_model=all_model, tflite_model=tflite_model)\n",
    "\n",
    "    display_tflite_classify_pose(cap, model=tflite_model)\n",
    "    # save_tflite_classify_pose(cap, model=tflite_model, result_out=output_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_train_pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.6.0\n",
      "  Using cached tensorflow_gpu-2.6.0-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.6.0) (1.1.2)\n",
      "Requirement already satisfied: keras~=2.6 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.6.0) (2.8.0)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 563 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.6.0) (1.1.0)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.6.0) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.6.0) (1.46.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.6.0) (1.6.3)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard~=2.6 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.6.0) (2.8.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.6.0) (3.20.1)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.6.0) (0.2.0)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (2.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (45.2.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/rakiiibul/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (2.6.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/rakiiibul/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.6.0) (4.11.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.6.0) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/rakiiibul/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/rakiiibul/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/rakiiibul/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0) (0.2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/rakiiibul/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.6.0) (3.8.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.6.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/rakiiibul/.local/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0) (0.4.8)\n",
      "Building wheels for collected packages: clang, wrapt\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=3869bef3e473e29104c7c1b4897e4f92806d43cf811635b6f2f4513ac65cdd8b\n",
      "  Stored in directory: /home/rakiiibul/.cache/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=78522 sha256=34226892100fb55445f8eb425f90896c42754d71ee49ca4863a9828ddf7bd999\n",
      "  Stored in directory: /home/rakiiibul/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built clang wrapt\n",
      "\u001b[31mERROR: launchpadlib 1.10.13 requires testresources, which is not installed.\u001b[0m\n",
      "Installing collected packages: typing-extensions, numpy, wheel, gast, clang, tensorflow-estimator, six, flatbuffers, absl-py, wrapt, h5py, tensorflow-gpu\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.2.0\n",
      "    Uninstalling typing-extensions-4.2.0:\n",
      "      Successfully uninstalled typing-extensions-4.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.3\n",
      "    Uninstalling numpy-1.22.3:\n",
      "      Successfully uninstalled numpy-1.22.3\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.0.0\n",
      "    Uninstalling absl-py-1.0.0:\n",
      "      Successfully uninstalled absl-py-1.0.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.14.1\n",
      "    Uninstalling wrapt-1.14.1:\n",
      "      Successfully uninstalled wrapt-1.14.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.6.0\n",
      "    Uninstalling h5py-3.6.0:\n",
      "      Successfully uninstalled h5py-3.6.0\n",
      "Successfully installed absl-py-0.15.0 clang-5.0 flatbuffers-1.12 gast-0.4.0 h5py-3.1.0 numpy-1.19.5 six-1.15.0 tensorflow-estimator-2.8.0 tensorflow-gpu-2.6.0 typing-extensions-3.7.4.3 wheel-0.37.1 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 2.8.0\n",
      "Uninstalling keras-2.8.0:\n",
      "  Would remove:\n",
      "    /home/rakiiibul/.local/lib/python3.8/site-packages/keras-2.8.0.dist-info/*\n",
      "    /home/rakiiibul/.local/lib/python3.8/site-packages/keras/*\n",
      "Proceed (y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "\u001b[33mWARNING: Skipping Tensorflow as it is not installed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip uninstall keras\n",
    "!pip uninstall Tensorflow\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_cpp_MIN_LEVEL'] =  '2'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 2.8.0\n",
      "Uninstalling keras-2.8.0:\n",
      "  Would remove:\n",
      "    /home/rakiiibul/.local/lib/python3.8/site-packages/keras-2.8.0.dist-info/*\n",
      "    /home/rakiiibul/.local/lib/python3.8/site-packages/keras/*\n",
      "Proceed (y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "Successfully installed keras-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/__init__.py:41\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/__init__.py?line=37'>38</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_six\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/__init__.py?line=38'>39</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/__init__.py?line=40'>41</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/__init__.py?line=41'>42</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/__init__.py?line=43'>44</a>\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py:49\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=46'>47</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=47'>48</a>\u001b[0m \u001b[39m# from tensorflow.python import keras\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=48'>49</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_column_lib \u001b[39mas\u001b[39;00m feature_column\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=49'>50</a>\u001b[0m \u001b[39m# from tensorflow.python.layers import layers\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=50'>51</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodule\u001b[39;00m \u001b[39mimport\u001b[39;00m module\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py?line=20'>21</a>\u001b[0m \u001b[39m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequence_feature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py:147\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py?line=144'>145</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_tensor \u001b[39mas\u001b[39;00m sparse_tensor_lib\n\u001b[1;32m    <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py?line=145'>146</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n\u001b[0;32m--> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py?line=146'>147</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[1;32m    <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py?line=147'>148</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n\u001b[1;32m    <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py?line=148'>149</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m check_ops\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m division\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy_tf_layers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py?line=21'>22</a>\u001b[0m InputSpec \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mInputSpec\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py?line=23'>24</a>\u001b[0m keras_style_scope \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mkeras_style_scope\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py?line=23'>24</a>\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics \u001b[39mas\u001b[39;00m metrics_module\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v1\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m functional\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py?line=31'>32</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py?line=32'>33</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py?line=33'>34</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py?line=34'>35</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py?line=35'>36</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py?line=14'>15</a>\u001b[0m \u001b[39m\"\"\"Built-in activation functions.\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m advanced_activations\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_object\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m serialize_keras_object\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_preprocessing_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m PreprocessingLayer\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py?line=27'>28</a>\u001b[0m \u001b[39m# Image preprocessing layers.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py?line=28'>29</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_preprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m CenterCrop\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py?line=29'>30</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_preprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomCrop\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py?line=30'>31</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_preprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomFlip\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_preprocessing_layer\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m InputSpec\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py?line=28'>29</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m image \u001b[39mas\u001b[39;00m image_preprocessing\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py?line=29'>30</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m control_flow_util\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py?line=30'>31</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=14'>15</a>\u001b[0m \u001b[39m\"\"\"Provides keras data preprocessing utils to pre-process tf.data.Datasets before they are fed to the model.\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=15'>16</a>\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=16'>17</a>\u001b[0m \u001b[39m# TODO(mihaimaruseac): remove the import of keras_preprocessing and injecting\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=17'>18</a>\u001b[0m \u001b[39m# once we update to latest version of keras_preprocessing\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=18'>19</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras_preprocessing\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_preprocessing'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 23:23:11.290932: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-13 23:23:11.290966: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39m#import os\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000012?line=1'>2</a>\u001b[0m \u001b[39m#os.environ[\"SM_FRAMEWORK\"] =  \"tf.keras\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000012?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000012?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/__init__.py:41\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/__init__.py?line=37'>38</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_six\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/__init__.py?line=38'>39</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/__init__.py?line=40'>41</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/__init__.py?line=41'>42</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/__init__.py?line=43'>44</a>\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py:49\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=46'>47</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=47'>48</a>\u001b[0m \u001b[39m# from tensorflow.python import keras\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=48'>49</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_column_lib \u001b[39mas\u001b[39;00m feature_column\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=49'>50</a>\u001b[0m \u001b[39m# from tensorflow.python.layers import layers\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=50'>51</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodule\u001b[39;00m \u001b[39mimport\u001b[39;00m module\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py?line=20'>21</a>\u001b[0m \u001b[39m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequence_feature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py:147\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py?line=144'>145</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_tensor \u001b[39mas\u001b[39;00m sparse_tensor_lib\n\u001b[1;32m    <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py?line=145'>146</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n\u001b[0;32m--> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py?line=146'>147</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[1;32m    <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py?line=147'>148</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n\u001b[1;32m    <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py?line=148'>149</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m check_ops\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m division\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy_tf_layers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py?line=21'>22</a>\u001b[0m InputSpec \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mInputSpec\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/layers/base.py?line=23'>24</a>\u001b[0m keras_style_scope \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mkeras_style_scope\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py?line=23'>24</a>\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics \u001b[39mas\u001b[39;00m metrics_module\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v1\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m functional\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py?line=31'>32</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py?line=32'>33</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py?line=33'>34</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py?line=34'>35</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py?line=35'>36</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py?line=14'>15</a>\u001b[0m \u001b[39m\"\"\"Built-in activation functions.\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m advanced_activations\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_object\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m serialize_keras_object\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_preprocessing_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m PreprocessingLayer\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py?line=27'>28</a>\u001b[0m \u001b[39m# Image preprocessing layers.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py?line=28'>29</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_preprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m CenterCrop\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py?line=29'>30</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_preprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomCrop\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py?line=30'>31</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_preprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomFlip\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_preprocessing_layer\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m InputSpec\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py?line=28'>29</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m image \u001b[39mas\u001b[39;00m image_preprocessing\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py?line=29'>30</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m control_flow_util\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py?line=30'>31</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=14'>15</a>\u001b[0m \u001b[39m\"\"\"Provides keras data preprocessing utils to pre-process tf.data.Datasets before they are fed to the model.\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=15'>16</a>\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=16'>17</a>\u001b[0m \u001b[39m# TODO(mihaimaruseac): remove the import of keras_preprocessing and injecting\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=17'>18</a>\u001b[0m \u001b[39m# once we update to latest version of keras_preprocessing\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=18'>19</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras_preprocessing\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     <a href='file:///home/rakiiibul/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_preprocessing'"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ[\"SM_FRAMEWORK\"] =  \"tf.keras\"\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "#from tensorflow.keras.layers import Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 336>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000013?line=343'>344</a>\u001b[0m all_model \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./model_weights/all_model/08.31_xyzv/3_categories_pose\u001b[39m\u001b[39m'\u001b[39m \u001b[39m# all_model: Model struct and model weights.\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000013?line=345'>346</a>\u001b[0m \u001b[39m# Data preprocessed and creat datasets.\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000013?line=346'>347</a>\u001b[0m pose_datasets \u001b[39m=\u001b[39m CsvDataset(file\u001b[39m=\u001b[39;49mdataset_csv_file)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000013?line=347'>348</a>\u001b[0m df_pose \u001b[39m=\u001b[39m pose_datasets\u001b[39m.\u001b[39mcsv_preprocessing()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000013?line=348'>349</a>\u001b[0m train_ds, val_ds \u001b[39m=\u001b[39m pose_datasets\u001b[39m.\u001b[39mdf_to_datasets(dataframe\u001b[39m=\u001b[39mdf_pose, target\u001b[39m=\u001b[39mtarget_value)\n",
      "\u001b[1;32m/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb Cell 14'\u001b[0m in \u001b[0;36mCsvDataset.__init__\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000013?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, file):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000013?line=3'>4</a>\u001b[0m     \u001b[39m# self.dataframe = pd.read_csv(file)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000013?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000013?line=5'>6</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_df \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rakiiibul/Desktop/mediapipe_pose_classification_with_tf-main/pose.ipynb#ch0000013?line=6'>7</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_df \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class CsvDataset:\n",
    "\n",
    "    def __init__(self, file):\n",
    "        # self.dataframe = pd.read_csv(file)\n",
    "        self.dataframe = pd.read_csv(file)\n",
    "        self.val_df = None\n",
    "        self.train_df = None\n",
    "        self.val_ds = None\n",
    "        self.train_ds = None\n",
    "\n",
    "    def csv_preprocessing(self):\n",
    "        ''''Remove points 1 to points 11 of columns.'''\n",
    "\n",
    "        # headers = [*pd.read_csv(dataset_csv_file, nrows=1)]\n",
    "        # df1 = pd.read_csv(dataset_csv_file, usecols=[c for c in headers if c != 'name'])\n",
    "\n",
    "        df2 = self.dataframe.copy()\n",
    "\n",
    "        columns_removed = [\n",
    "            'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11',\n",
    "            'y1', 'y2', 'y3', 'y4', 'y5', 'y6', 'y7', 'y8', 'y9', 'y10', 'y11',\n",
    "            'z1', 'z2', 'z3', 'z4', 'z5', 'z6', 'z7', 'z8', 'z9', 'z10', 'z11',\n",
    "            'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11',\n",
    "\n",
    "            # 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21',\n",
    "            # 'v22', 'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'v29', 'v30', 'v31',\n",
    "            # 'v32', 'v33',\n",
    "        ]\n",
    "\n",
    "        df2 = df2.drop(columns_removed, axis = 'columns')\n",
    "\n",
    "        # print('*'*60)\n",
    "        # print(f'df1: \\n{self.dataframe.head()}')\n",
    "        # print(f'df2: \\n{df2.head()}')\n",
    "        return df2\n",
    "    \n",
    "    def df_to_datasets(self, dataframe, target):\n",
    "        ''''Input pandas dataframe to get specific features dataset of datasets.'''\n",
    "\n",
    "        # frac(float): 要抽出的比例, random_state：隨機的狀態.\n",
    "        self.val_df = dataframe.sample(frac=0.2, random_state=1337)\n",
    "        # drop the colum 1 of 'class'.\n",
    "        self.train_df = dataframe.drop(self.val_df.index)\n",
    "\n",
    "        train_df = self.train_df.copy()\n",
    "        val_df = self.val_df.copy()\n",
    "\n",
    "        train_labels = train_df.pop(target)\n",
    "        val_labels = val_df.pop(target)\n",
    "        \n",
    "        # tf.data.Dataset.from_tensor_slices(): 可以獲取列表或數組的切片。\n",
    "        self.train_ds = tf.data.Dataset.from_tensor_slices((dict(train_df), train_labels))\n",
    "        self.val_ds = tf.data.Dataset.from_tensor_slices((dict(val_df), val_labels))\n",
    "\n",
    "        # shuffle(): 用來打亂數據集中數據順序.\n",
    "        # buffer_size: https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/661458/\n",
    "        self.train_ds = self.train_ds.shuffle(buffer_size=len(self.train_ds))\n",
    "        self.val_ds = self.val_ds.shuffle(buffer_size=len(self.val_ds))\n",
    "\n",
    "        return self.train_ds, self.val_ds\n",
    "\n",
    "\n",
    "class EncodeFeatures:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.feature_ds = None\n",
    "            \n",
    "    def numerical_feature(self, feature, name, dataset):\n",
    "        # Create a Normalization layer for our feature\n",
    "        normalizer = Normalization()\n",
    "\n",
    "        # Prepare a Dataset that only yields our feature\n",
    "        self.feature_ds = dataset.map(lambda x, y: x[name])\n",
    "        self.feature_ds = self.feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "        # Learn the statistics of the data\n",
    "        normalizer.adapt(self.feature_ds)\n",
    "\n",
    "        # Normalize the input feature\n",
    "        encoded_feature = normalizer(feature)\n",
    "        return encoded_feature\n",
    "\n",
    "\n",
    "def point():\n",
    "    x = [\n",
    "        'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22',\n",
    "        'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'x31', 'x32', 'x33',\n",
    "    ]\n",
    "    y = [\n",
    "        'y12', 'y13', 'y14', 'y15', 'y16', 'y17', 'y18', 'y19', 'y20', 'y21', 'y22',\n",
    "        'y23', 'y24', 'y25', 'y26', 'y27', 'y28', 'y29', 'y30', 'y31', 'y32', 'y33',\n",
    "    ]\n",
    "    z = [\n",
    "        'z12', 'z13', 'z14', 'z15', 'z16', 'z17', 'z18', 'z19', 'z20', 'z21', 'z22',\n",
    "        'z23', 'z24', 'z25', 'z26', 'z27', 'z28', 'z29', 'z30', 'z31', 'z32', 'z33',\n",
    "    ]\n",
    "    v = [\n",
    "        'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21', 'v22',\n",
    "        'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'v29', 'v30', 'v31', 'v32', 'v33',\n",
    "    ]\n",
    "    coords = [x, y, z, v]\n",
    "    return coords\n",
    "\n",
    "\n",
    "def input_features():\n",
    "\n",
    "    coords = point()\n",
    "    # point 12 ~ 33\n",
    "    # Numerical features\n",
    "    x12 = keras.Input(shape=(1,), name=coords[0][0])\n",
    "    x13 = keras.Input(shape=(1,), name=coords[0][1])\n",
    "    x14 = keras.Input(shape=(1,), name=coords[0][2])\n",
    "    x15 = keras.Input(shape=(1,), name=coords[0][3])\n",
    "    x16 = keras.Input(shape=(1,), name=coords[0][4])\n",
    "    x17 = keras.Input(shape=(1,), name=coords[0][5]) \n",
    "    x18 = keras.Input(shape=(1,), name=coords[0][6])\n",
    "    x19 = keras.Input(shape=(1,), name=coords[0][7])\n",
    "    x20 = keras.Input(shape=(1,), name=coords[0][8])\n",
    "    x21 = keras.Input(shape=(1,), name=coords[0][9])\n",
    "    x22 = keras.Input(shape=(1,), name=coords[0][10])\n",
    "    x23 = keras.Input(shape=(1,), name=coords[0][11])\n",
    "    x24 = keras.Input(shape=(1,), name=coords[0][12])\n",
    "    x25 = keras.Input(shape=(1,), name=coords[0][13])\n",
    "    x26 = keras.Input(shape=(1,), name=coords[0][14])\n",
    "    x27 = keras.Input(shape=(1,), name=coords[0][15])\n",
    "    x28 = keras.Input(shape=(1,), name=coords[0][16])\n",
    "    x29 = keras.Input(shape=(1,), name=coords[0][17])\n",
    "    x30 = keras.Input(shape=(1,), name=coords[0][18])\n",
    "    x31 = keras.Input(shape=(1,), name=coords[0][19])\n",
    "    x32 = keras.Input(shape=(1,), name=coords[0][20])\n",
    "    x33 = keras.Input(shape=(1,), name=coords[0][21])\n",
    "\n",
    "    y12 = keras.Input(shape=(1,), name=coords[1][0])\n",
    "    y13 = keras.Input(shape=(1,), name=coords[1][1])\n",
    "    y14 = keras.Input(shape=(1,), name=coords[1][2])\n",
    "    y15 = keras.Input(shape=(1,), name=coords[1][3])\n",
    "    y16 = keras.Input(shape=(1,), name=coords[1][4])\n",
    "    y17 = keras.Input(shape=(1,), name=coords[1][5]) \n",
    "    y18 = keras.Input(shape=(1,), name=coords[1][6])\n",
    "    y19 = keras.Input(shape=(1,), name=coords[1][7])\n",
    "    y20 = keras.Input(shape=(1,), name=coords[1][8])\n",
    "    y21 = keras.Input(shape=(1,), name=coords[1][9])\n",
    "    y22 = keras.Input(shape=(1,), name=coords[1][10])\n",
    "    y23 = keras.Input(shape=(1,), name=coords[1][11])\n",
    "    y24 = keras.Input(shape=(1,), name=coords[1][12])\n",
    "    y25 = keras.Input(shape=(1,), name=coords[1][13])\n",
    "    y26 = keras.Input(shape=(1,), name=coords[1][14])\n",
    "    y27 = keras.Input(shape=(1,), name=coords[1][15])\n",
    "    y28 = keras.Input(shape=(1,), name=coords[1][16])\n",
    "    y29 = keras.Input(shape=(1,), name=coords[1][17])\n",
    "    y30 = keras.Input(shape=(1,), name=coords[1][18])\n",
    "    y31 = keras.Input(shape=(1,), name=coords[1][19])\n",
    "    y32 = keras.Input(shape=(1,), name=coords[1][20])\n",
    "    y33 = keras.Input(shape=(1,), name=coords[1][21])\n",
    "\n",
    "    z12 = keras.Input(shape=(1,), name=coords[2][0])\n",
    "    z13 = keras.Input(shape=(1,), name=coords[2][1])\n",
    "    z14 = keras.Input(shape=(1,), name=coords[2][2])\n",
    "    z15 = keras.Input(shape=(1,), name=coords[2][3])\n",
    "    z16 = keras.Input(shape=(1,), name=coords[2][4])\n",
    "    z17 = keras.Input(shape=(1,), name=coords[2][5]) \n",
    "    z18 = keras.Input(shape=(1,), name=coords[2][6])\n",
    "    z19 = keras.Input(shape=(1,), name=coords[2][7])\n",
    "    z20 = keras.Input(shape=(1,), name=coords[2][8])\n",
    "    z21 = keras.Input(shape=(1,), name=coords[2][9])\n",
    "    z22 = keras.Input(shape=(1,), name=coords[2][10])\n",
    "    z23 = keras.Input(shape=(1,), name=coords[2][11])\n",
    "    z24 = keras.Input(shape=(1,), name=coords[2][12])\n",
    "    z25 = keras.Input(shape=(1,), name=coords[2][13])\n",
    "    z26 = keras.Input(shape=(1,), name=coords[2][14])\n",
    "    z27 = keras.Input(shape=(1,), name=coords[2][15])\n",
    "    z28 = keras.Input(shape=(1,), name=coords[2][16])\n",
    "    z29 = keras.Input(shape=(1,), name=coords[2][17])\n",
    "    z30 = keras.Input(shape=(1,), name=coords[2][18])\n",
    "    z31 = keras.Input(shape=(1,), name=coords[2][19])\n",
    "    z32 = keras.Input(shape=(1,), name=coords[2][20])\n",
    "    z33 = keras.Input(shape=(1,), name=coords[2][21])\n",
    "\n",
    "    v12 = keras.Input(shape=(1,), name=coords[3][0])\n",
    "    v13 = keras.Input(shape=(1,), name=coords[3][1])\n",
    "    v14 = keras.Input(shape=(1,), name=coords[3][2])\n",
    "    v15 = keras.Input(shape=(1,), name=coords[3][3])\n",
    "    v16 = keras.Input(shape=(1,), name=coords[3][4])\n",
    "    v17 = keras.Input(shape=(1,), name=coords[3][5]) \n",
    "    v18 = keras.Input(shape=(1,), name=coords[3][6])\n",
    "    v19 = keras.Input(shape=(1,), name=coords[3][7])\n",
    "    v20 = keras.Input(shape=(1,), name=coords[3][8])\n",
    "    v21 = keras.Input(shape=(1,), name=coords[3][9])\n",
    "    v22 = keras.Input(shape=(1,), name=coords[3][10])\n",
    "    v23 = keras.Input(shape=(1,), name=coords[3][11])\n",
    "    v24 = keras.Input(shape=(1,), name=coords[3][12])\n",
    "    v25 = keras.Input(shape=(1,), name=coords[3][13])\n",
    "    v26 = keras.Input(shape=(1,), name=coords[3][14])\n",
    "    v27 = keras.Input(shape=(1,), name=coords[3][15])\n",
    "    v28 = keras.Input(shape=(1,), name=coords[3][16])\n",
    "    v29 = keras.Input(shape=(1,), name=coords[3][17])\n",
    "    v30 = keras.Input(shape=(1,), name=coords[3][18])\n",
    "    v31 = keras.Input(shape=(1,), name=coords[3][19])\n",
    "    v32 = keras.Input(shape=(1,), name=coords[3][20])\n",
    "    v33 = keras.Input(shape=(1,), name=coords[3][21])\n",
    "\n",
    "    all_inputs = [\n",
    "        x12, x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, \n",
    "        x23, x24, x25, x26, x27, x28, x29, x30, x31, x32, x33,\n",
    "\n",
    "        y12, y13, y14, y15, y16, y17, y18, y19, y20, y21, y22, \n",
    "        y23, y24, y25, y26, y27, y28, y29, y30, y31, y32, y33,\n",
    "\n",
    "        z12, z13, z14, z15, z16, z17, z18, z19, z20, z21, z22, \n",
    "        z23, z24, z25, z26, z27, z28, z29, z30, z31, z32, z33,\n",
    "\n",
    "        v12, v13, v14, v15, v16, v17, v18, v19, v20, v21, v22, \n",
    "        v23, v24, v25, v26, v27, v28, v29, v30, v31, v32, v33,\n",
    "    ]\n",
    "\n",
    "    return all_inputs\n",
    "\n",
    "\n",
    "def specify_encoded_features(train_ds, all_inputs):\n",
    "\n",
    "    encoded = EncodeFeatures()\n",
    "    coords_p = point()\n",
    "\n",
    "    # point 12 ~ 33\n",
    "    # Numerical features\n",
    "    x12 = encoded.numerical_feature(all_inputs[0], coords_p[0][0], train_ds)\n",
    "    x13 = encoded.numerical_feature(all_inputs[1], coords_p[0][1], train_ds)\n",
    "    x14 = encoded.numerical_feature(all_inputs[2], coords_p[0][2], train_ds)\n",
    "    x15 = encoded.numerical_feature(all_inputs[3], coords_p[0][3], train_ds)\n",
    "    x16 = encoded.numerical_feature(all_inputs[4], coords_p[0][4], train_ds)\n",
    "    x17 = encoded.numerical_feature(all_inputs[5], coords_p[0][5], train_ds)\n",
    "    x18 = encoded.numerical_feature(all_inputs[6], coords_p[0][6], train_ds)\n",
    "    x19 = encoded.numerical_feature(all_inputs[7], coords_p[0][7], train_ds)\n",
    "    x20 = encoded.numerical_feature(all_inputs[8], coords_p[0][8], train_ds)\n",
    "    x21 = encoded.numerical_feature(all_inputs[9], coords_p[0][9], train_ds)\n",
    "    x22 = encoded.numerical_feature(all_inputs[10], coords_p[0][10], train_ds)\n",
    "    x23 = encoded.numerical_feature(all_inputs[11], coords_p[0][11], train_ds)\n",
    "    x24 = encoded.numerical_feature(all_inputs[12], coords_p[0][12], train_ds)\n",
    "    x25 = encoded.numerical_feature(all_inputs[13], coords_p[0][13], train_ds)\n",
    "    x26 = encoded.numerical_feature(all_inputs[14], coords_p[0][14], train_ds)\n",
    "    x27 = encoded.numerical_feature(all_inputs[15], coords_p[0][15], train_ds)\n",
    "    x28 = encoded.numerical_feature(all_inputs[16], coords_p[0][16], train_ds)\n",
    "    x29 = encoded.numerical_feature(all_inputs[17], coords_p[0][17], train_ds)\n",
    "    x30 = encoded.numerical_feature(all_inputs[18], coords_p[0][18], train_ds)\n",
    "    x31 = encoded.numerical_feature(all_inputs[19], coords_p[0][19], train_ds)\n",
    "    x32 = encoded.numerical_feature(all_inputs[20], coords_p[0][20], train_ds)\n",
    "    x33 = encoded.numerical_feature(all_inputs[21], coords_p[0][21], train_ds)\n",
    "\n",
    "    y12 = encoded.numerical_feature(all_inputs[22], coords_p[1][0], train_ds)\n",
    "    y13 = encoded.numerical_feature(all_inputs[23], coords_p[1][1], train_ds)\n",
    "    y14 = encoded.numerical_feature(all_inputs[24], coords_p[1][2], train_ds)\n",
    "    y15 = encoded.numerical_feature(all_inputs[25], coords_p[1][3], train_ds)\n",
    "    y16 = encoded.numerical_feature(all_inputs[26], coords_p[1][4], train_ds)\n",
    "    y17 = encoded.numerical_feature(all_inputs[27], coords_p[1][5], train_ds)\n",
    "    y18 = encoded.numerical_feature(all_inputs[28], coords_p[1][6], train_ds)\n",
    "    y19 = encoded.numerical_feature(all_inputs[29], coords_p[1][7], train_ds)\n",
    "    y20 = encoded.numerical_feature(all_inputs[30], coords_p[1][8], train_ds)\n",
    "    y21 = encoded.numerical_feature(all_inputs[31], coords_p[1][9], train_ds)\n",
    "    y22 = encoded.numerical_feature(all_inputs[32], coords_p[1][10], train_ds)\n",
    "    y23 = encoded.numerical_feature(all_inputs[33], coords_p[1][11], train_ds)\n",
    "    y24 = encoded.numerical_feature(all_inputs[34], coords_p[1][12], train_ds)\n",
    "    y25 = encoded.numerical_feature(all_inputs[35], coords_p[1][13], train_ds)\n",
    "    y26 = encoded.numerical_feature(all_inputs[36], coords_p[1][14], train_ds)\n",
    "    y27 = encoded.numerical_feature(all_inputs[37], coords_p[1][15], train_ds)\n",
    "    y28 = encoded.numerical_feature(all_inputs[38], coords_p[1][16], train_ds)\n",
    "    y29 = encoded.numerical_feature(all_inputs[39], coords_p[1][17], train_ds)\n",
    "    y30 = encoded.numerical_feature(all_inputs[40], coords_p[1][18], train_ds)\n",
    "    y31 = encoded.numerical_feature(all_inputs[41], coords_p[1][19], train_ds)\n",
    "    y32 = encoded.numerical_feature(all_inputs[42], coords_p[1][20], train_ds)\n",
    "    y33 = encoded.numerical_feature(all_inputs[43], coords_p[1][21], train_ds)\n",
    "\n",
    "    z12 = encoded.numerical_feature(all_inputs[44], coords_p[2][0], train_ds)\n",
    "    z13 = encoded.numerical_feature(all_inputs[45], coords_p[2][1], train_ds)\n",
    "    z14 = encoded.numerical_feature(all_inputs[46], coords_p[2][2], train_ds)\n",
    "    z15 = encoded.numerical_feature(all_inputs[47], coords_p[2][3], train_ds)\n",
    "    z16 = encoded.numerical_feature(all_inputs[48], coords_p[2][4], train_ds)\n",
    "    z17 = encoded.numerical_feature(all_inputs[49], coords_p[2][5], train_ds)\n",
    "    z18 = encoded.numerical_feature(all_inputs[50], coords_p[2][6], train_ds)\n",
    "    z19 = encoded.numerical_feature(all_inputs[51], coords_p[2][7], train_ds)\n",
    "    z20 = encoded.numerical_feature(all_inputs[52], coords_p[2][8], train_ds)\n",
    "    z21 = encoded.numerical_feature(all_inputs[53], coords_p[2][9], train_ds)\n",
    "    z22 = encoded.numerical_feature(all_inputs[54], coords_p[2][10], train_ds)\n",
    "    z23 = encoded.numerical_feature(all_inputs[55], coords_p[2][11], train_ds)\n",
    "    z24 = encoded.numerical_feature(all_inputs[56], coords_p[2][12], train_ds)\n",
    "    z25 = encoded.numerical_feature(all_inputs[57], coords_p[2][13], train_ds)\n",
    "    z26 = encoded.numerical_feature(all_inputs[58], coords_p[2][14], train_ds)\n",
    "    z27 = encoded.numerical_feature(all_inputs[59], coords_p[2][15], train_ds)\n",
    "    z28 = encoded.numerical_feature(all_inputs[60], coords_p[2][16], train_ds)\n",
    "    z29 = encoded.numerical_feature(all_inputs[61], coords_p[2][17], train_ds)\n",
    "    z30 = encoded.numerical_feature(all_inputs[62], coords_p[2][18], train_ds)\n",
    "    z31 = encoded.numerical_feature(all_inputs[63], coords_p[2][19], train_ds)\n",
    "    z32 = encoded.numerical_feature(all_inputs[64], coords_p[2][20], train_ds)\n",
    "    z33 = encoded.numerical_feature(all_inputs[65], coords_p[2][21], train_ds)\n",
    "\n",
    "    v12 = encoded.numerical_feature(all_inputs[66], coords_p[3][0], train_ds)\n",
    "    v13 = encoded.numerical_feature(all_inputs[67], coords_p[3][1], train_ds)\n",
    "    v14 = encoded.numerical_feature(all_inputs[68], coords_p[3][2], train_ds)\n",
    "    v15 = encoded.numerical_feature(all_inputs[69], coords_p[3][3], train_ds)\n",
    "    v16 = encoded.numerical_feature(all_inputs[70], coords_p[3][4], train_ds)\n",
    "    v17 = encoded.numerical_feature(all_inputs[71], coords_p[3][5], train_ds)\n",
    "    v18 = encoded.numerical_feature(all_inputs[72], coords_p[3][6], train_ds)\n",
    "    v19 = encoded.numerical_feature(all_inputs[73], coords_p[3][7], train_ds)\n",
    "    v20 = encoded.numerical_feature(all_inputs[74], coords_p[3][8], train_ds)\n",
    "    v21 = encoded.numerical_feature(all_inputs[75], coords_p[3][9], train_ds)\n",
    "    v22 = encoded.numerical_feature(all_inputs[76], coords_p[3][10], train_ds)\n",
    "    v23 = encoded.numerical_feature(all_inputs[77], coords_p[3][11], train_ds)\n",
    "    v24 = encoded.numerical_feature(all_inputs[78], coords_p[3][12], train_ds)\n",
    "    v25 = encoded.numerical_feature(all_inputs[79], coords_p[3][13], train_ds)\n",
    "    v26 = encoded.numerical_feature(all_inputs[80], coords_p[3][14], train_ds)\n",
    "    v27 = encoded.numerical_feature(all_inputs[81], coords_p[3][15], train_ds)\n",
    "    v28 = encoded.numerical_feature(all_inputs[82], coords_p[3][16], train_ds)\n",
    "    v29 = encoded.numerical_feature(all_inputs[83], coords_p[3][17], train_ds)\n",
    "    v30 = encoded.numerical_feature(all_inputs[84], coords_p[3][18], train_ds)\n",
    "    v31 = encoded.numerical_feature(all_inputs[85], coords_p[3][19], train_ds)\n",
    "    v32 = encoded.numerical_feature(all_inputs[86], coords_p[3][20], train_ds)\n",
    "    v33 = encoded.numerical_feature(all_inputs[87], coords_p[3][21], train_ds)\n",
    "\n",
    "    all_features = layers.concatenate(\n",
    "        [\n",
    "            x12, x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, \n",
    "            x23, x24, x25, x26, x27, x28, x29, x30, x31, x32, x33,\n",
    "\n",
    "            y12, y13, y14, y15, y16, y17, y18, y19, y20, y21, y22,\n",
    "            y23, y24, y25, y26, y27, y28, y29, y30, y31, y32, y33,\n",
    "\n",
    "            z12, z13, z14, z15, z16, z17, z18, z19, z20, z21, z22, \n",
    "            z23, z24, z25, z26, z27, z28, z29, z30, z31, z32, z33,\n",
    "\n",
    "            v12, v13, v14, v15, v16, v17, v18, v19, v20, v21, v22,\n",
    "            v23, v24, v25, v26, v27, v28, v29, v30, v31, v32, v33,\n",
    "        ]\n",
    "    )\n",
    "    return all_features\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Config TF to use GPU.\n",
    "    #physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    #tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "    dataset_csv_file = '2.csv'\n",
    "    target_value = 'class'\n",
    "    all_model = './model_weights/all_model/08.31_xyzv/3_categories_pose' # all_model: Model struct and model weights.\n",
    "\n",
    "    # Data preprocessed and creat datasets.\n",
    "    pose_datasets = CsvDataset(file=dataset_csv_file)\n",
    "    df_pose = pose_datasets.csv_preprocessing()\n",
    "    train_ds, val_ds = pose_datasets.df_to_datasets(dataframe=df_pose, target=target_value)\n",
    "\n",
    "    # # .take(n): get n datas.\n",
    "    # for x, y in train_ds.take(1):\n",
    "    #     # tf.print('Input(Features):', x)\n",
    "    #     print('Target:', y)\n",
    "\n",
    "    train_ds = train_ds.batch(32)\n",
    "    val_ds = val_ds.batch(32)\n",
    "\n",
    "    # Functional API model build.\n",
    "    all_inputs = input_features()\n",
    "    all_features = specify_encoded_features(train_ds, all_inputs)\n",
    "    x = layers.Dense(32, activation='relu')(all_features)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    # output = layers.Dense(3, activation='sigmoid')(x) # from_logits=False\n",
    "    output = layers.Dense(3, activation='softmax')(x) # from_logits=False\n",
    "    model = keras.Model(all_inputs, output)\n",
    "\n",
    "    # logits 表示網絡的直接輸出。  \n",
    "    # 没經過 sigmoid或者softmax的概率化。\n",
    "    # from_logits=False 表示把已經概率化了的输出，重回原值。 \n",
    "    model.compile(optimizer='sgd', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "\n",
    "    # Model train.\n",
    "    model.fit(x=train_ds, epochs=100, verbose=2, validation_data=val_ds)\n",
    "\n",
    "    # # Option1: Save Keras model. # #\n",
    "    # model.save(all_model)\n",
    "    # print('Model save done!')\n",
    "\n",
    "    # # Option2: Save TFLite model. # #\n",
    "    # Convert the model.\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open('model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "    print('TFLite Model save done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip uninstall keras -y\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
