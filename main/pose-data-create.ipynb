{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detections(cap):\n",
    "    '''# 1. Make Some Detections with a video # '''\n",
    "    if (cap.isOpened() == False):\n",
    "        print(\"Error opening the video file.\")\n",
    "    else:\n",
    "        input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(f'Frames per second: {input_fps}')\n",
    "        print(f'Frame count: {frame_count}')\n",
    "    \n",
    "    # Color difine\n",
    "    #color_face1 = (71, 146, 253)\n",
    "    color_face2 = (71, 146, 253)\n",
    "    color_r_hand1 = (71, 146, 253)\n",
    "    color_r_hand2 = (71, 146, 253)\n",
    "    color_l_hand1 = (71, 146, 253)\n",
    "    color_l_hand2 = (71, 146, 253)\n",
    "    color_pose1 = (71, 146, 253)\n",
    "    color_pose2 = (71, 146, 253)\n",
    "\n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils # Drawing helpers.\n",
    "    mp_holistic = mp.solutions.holistic     # Mediapipe Solutions.\n",
    "\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "                # print(results.face_landmarks)\n",
    "\n",
    "                # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                '''# 1. Draw face landmarks\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_face1, thickness=1, circle_radius=1),\n",
    "                    mp_drawing.DrawingSpec(color=color_face2, thickness=1, circle_radius=1)\n",
    "                )\n",
    "\n",
    "                # 2. Right hand\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_r_hand1, thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=color_r_hand2, thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_l_hand1, thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=color_l_hand2, thickness=2, circle_radius=2)\n",
    "                )'''\n",
    "\n",
    "                # 4. Pose Detections\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=(71, 146, 253), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(71, 146, 253), thickness=2, circle_radius=2)\n",
    "                )\n",
    "            \n",
    "\n",
    "                cv2.imshow('Raw Video Feed', image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    print('Done.')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_pose_csv(cap, create_csv):\n",
    "    ''' Create pose detections csv  with a video.'''\n",
    "    if (cap.isOpened() == False):\n",
    "        print(\"\\nError opening the video file.\")\n",
    "        return\n",
    "    else:\n",
    "        pass\n",
    "    # Color difine\n",
    "    color_pose1 = (245,117,66)\n",
    "    color_pose2 = (245,66,230)\n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils # Drawing helpers.\n",
    "    mp_holistic = mp.solutions.holistic     # Mediapipe Solutions.\n",
    "\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                # Pose Detections\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=color_pose1, thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=color_pose2, thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "                try:\n",
    "                    num_coords = len(results.pose_landmarks.landmark) # num_coords: 33\n",
    "\n",
    "                    landmarks = ['class'] # Create first rows data.\n",
    "                    for val in range(1, num_coords+1):\n",
    "                        landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "                    \n",
    "                    # E.g., (pose+face)2005=1+501*4, (pose+r_hand)217=1+54*4, 133=1+33*4\n",
    "                    # print(f'len(landmarks): {len(landmarks)}')\n",
    "\n",
    "                    # Define first class rows in csv file.\n",
    "                    with open(create_csv, mode='w', newline='') as f:\n",
    "                        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        csv_writer.writerow(landmarks)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                cv2.imshow('Raw Video Feed', image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print(f'\\nCreate {dataset_csv_file} done! \\n\\nNow you can run again.')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_record_coordinates(cap, class_name, export_csv):\n",
    "    if (cap.isOpened() == False):\n",
    "        print(\"Error opening the video file.\")\n",
    "    else:\n",
    "        input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(f'Frames per second: {input_fps}')\n",
    "        print(f'Frame count: {frame_count}')\n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils # Drawing helpers.\n",
    "    mp_holistic = mp.solutions.holistic     # Mediapipe Solutions.\n",
    "\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "                # print(results.face_landmarks)\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                #  Pose Detections\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                    mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                )\n",
    "                # Export coordinates\n",
    "                try:\n",
    "                    # Extract Pose landmarks\n",
    "                    pose = results.pose_landmarks.landmark\n",
    "                    pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "                    # Extract Face landmarks\n",
    "                    # face = results.face_landmarks.landmark\n",
    "                    row = pose_row\n",
    "\n",
    "                    # Append class name.\n",
    "                    row.insert(0, class_name)\n",
    "\n",
    "                    # Export to CSV\n",
    "                    with open(export_csv, mode='a', newline='') as f:\n",
    "                        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        csv_writer.writerow(row) \n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "    print('Add done!\\n -------------------')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # check_csv_contents(file=export_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_csv_contents(file=export_csv)\n",
    "def check_csv_contents(file):\n",
    "    df = pd.read_csv(file)\n",
    "    print(f'Top5 datas: \\n{df.head()}')\n",
    "    print(f'Last5 datas: \\n{df.tail()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv: Not exist.\n",
      "\n",
      "Initiate creating a csv file....\n",
      "\n",
      "\n",
      "Error opening the video file.\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "n = 0\n",
    "\n",
    "    # 0: cat_camel, 1: bridge_exercise, 2: heel_raise\n",
    "    category = [0, 1, 2]\n",
    "    video_file_name = 'cat_camel' + '2'\n",
    "    \n",
    "    # Add n categories of pose.\n",
    "    add_class = category[n]\n",
    "\n",
    "    # Can create train dataset or test dataset.\n",
    "    dataset_csv_file = 'data.csv'\n",
    "\n",
    "    video_path = \"./\" + video_file_name +\".mp4\"\n",
    "    output_video = video_file_name + \"_out.mp4\"\n",
    "\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if os.path.isfile(dataset_csv_file):\n",
    "        print (f'{dataset_csv_file}: Exist.')\n",
    "        print(f'Add class: {add_class} \\n-----------------')\n",
    "\n",
    "        add_record_coordinates(cap=cap, class_name=add_class, export_csv=dataset_csv_file)\n",
    "    else:\n",
    "        print (f'{dataset_csv_file}: Not exist.')\n",
    "        print('\\nInitiate creating a csv file....\\n')\n",
    "        create_pose_csv(cap, create_csv=dataset_csv_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
